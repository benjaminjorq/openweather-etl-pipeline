# ğŸŒ¤ï¸ OpenWeather ETL Pipeline

![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-336791?style=for-the-badge&logo=postgresql&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Container-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-Data_Processing-150458?style=for-the-badge&logo=pandas&logoColor=white)

##  Sobre el Proyecto

Este proyecto implementa un pipeline de datos batch **End-to-End** modularizado y contenerizado. Su objetivo es extraer datos climÃ¡ticos y de contaminaciÃ³n desde la API de OpenWeather (Current Weather Data & Air Pollution), procesarlos para asegurar su calidad y disponibilidad, y generar reportes analÃ­ticos.

El sistema simula un entorno productivo siguiendo la arquitectura **Medallion (Bronze/Silver/Gold)**, priorizando el manejo de errores, la limpieza de datos y la trazabilidad mediante logs.

<div align="center">
  <img width="100%" alt="pipeline_diagram" src="https://github.com/user-attachments/assets/bcb2a51a-2000-43da-ae69-8c0f2ee6b0ce" />
</div>

## ğŸ—ï¸ Arquitectura de Datos

El flujo estÃ¡ diseÃ±ado para transformar datos crudos en insights de negocio:

### 1. ğŸ¥‰ Bronze Layer (Ingesta Raw)
* **Fuente:** API OpenWeather (Endpoints `/weather` y `/air_pollution`).
* **Proceso:** ExtracciÃ³n vÃ­a `requests` validando cÃ³digos de estado HTTP (200 OK).
* **Almacenamiento:** Archivos JSON crudos guardados localmente para auditorÃ­a histÃ³rica.

### 2. ğŸ¥ˆ Silver Layer (Limpieza y NormalizaciÃ³n)
* **TransformaciÃ³n:**
    * **Flattening:** Aplanamiento de estructuras JSON anidadas (diccionarios dentro de listas) usando Python y Pandas.
    * **Data Quality:** ConversiÃ³n de tipos de datos, eliminaciÃ³n de duplicados y filtrado de valores atÃ­picos.
* **Almacenamiento:** Archivos **CSV** con particionamiento tipo Hive (`year=YYYY/month=MM/day=DD`) para optimizar la organizaciÃ³n y consulta.
* **Carga DB:** Ingesta de datos limpios hacia **PostgreSQL** mediante `SQLAlchemy`.

### 3. ğŸ¥‡ Gold Layer (Reportes de Negocio)
* **LÃ³gica de Negocio:** Enriquecimiento de datos aplicando reglas de clasificaciÃ³n (ej. Calidad de aire "Peligrosa" si PM2.5 > 55).
* **Outputs Generados:** Rankings de contaminaciÃ³n y resÃºmenes nacionales agrupados.

---

## ğŸ› ï¸ Tech Stack & LibrerÃ­as

El proyecto utiliza herramientas estÃ¡ndar de la industria, definidas en `requirements.txt`:

* **IngenierÃ­a:** `Python`, `Pandas` (ManipulaciÃ³n de DataFrames), `SQLAlchemy` (GestiÃ³n de ConexiÃ³n de Base de Datos).
* **Infraestructura:** `Docker` & `Docker Compose` (GestiÃ³n del entorno aislado)
* **ConfiguraciÃ³n:** `PyYAML` (GestiÃ³n de config de ciudades), `Python-dotenv` (Variables de entorno seguras).
* **Calidad:** `Pytest` (Tests unitarios), `Logging` (Trazabilidad de ejecuciÃ³n).

---

## âš™ï¸ OrquestaciÃ³n

La automatizaciÃ³n y el control del flujo de datos se gestionan con Apache Airflow. Su implementaciÃ³n permite coordinar las dependencias entre tareas, gestionar reintentos automÃ¡ticos y mantener un registro claro (logs) de cada ejecuciÃ³n para asegurar la calidad del dato.

<p align="center">
  <img width="965" alt="graph airflow" src="https://github.com/user-attachments/assets/28a59102-26b0-451a-a09c-b1a7b39b27f8" />
  <br>
  <em>Vista del DAG en Airflow: EjecuciÃ³n exitosa de todas las etapas del pipeline.</em>
</p>

---

### ğŸ“‘ Monitoreo y Logs

El sistema genera logs detallados en cada etapa para facilitar el monitoreo y asegurar la calidad de los datos. Puedes expandir cada secciÃ³n para ver la evidencia tÃ©cnica:

<details>
<summary><b>1. Ingesta de Datos (Bronze Layer)</b></summary>
Evidencia de la extracciÃ³n batch desde la API de OpenWeather y el almacenamiento exitoso de los datos crudos en formato JSON.
<br><br>
<img width="909" alt="log ingesta" src="https://github.com/user-attachments/assets/270fd292-4366-48b1-a6f6-447ad490480d" />
</details>

<details>
<summary><b>2. TransformaciÃ³n y Limpieza (Silver Layer)</b></summary>
Logs del proceso de limpieza, normalizaciÃ³n de esquemas y aplanamiento de estructuras anidadas mediante Pandas.
<br><br>
<img width="960" alt="log transform" src="https://github.com/user-attachments/assets/996f31d5-1670-4295-bae3-c1c9cdf1b99b" />
</details>

<details>
<summary><b>3. Carga a PostgreSQL</b></summary>
ConfirmaciÃ³n de la ingesta de datos limpios hacia la base de datos relacional PostgreSQL para persistencia a largo plazo.
<br><br>
<img width="827" alt="log load" src="https://github.com/user-attachments/assets/8fad41f9-e2f4-4204-9892-58e350c9cbe5" />
</details>

<details>
<summary><b>4. GeneraciÃ³n de Reportes (Gold Layer)</b></summary>
Evidencia de la lÃ³gica de negocio aplicada: creaciÃ³n de rankings de contaminaciÃ³n y resÃºmenes estadÃ­sticos con niveles de calidad de aire.
<br><br>
<img width="1085" alt="log gold" src="https://github.com/user-attachments/assets/7828776f-e364-41ff-834e-83a0853c4d40" />
</details>

---

## ğŸ“‚ Estructura del Repositorio

```bash
openweather-etl-pipeline/
â”œâ”€â”€ config/              # Configuraciones (YAML)
â”œâ”€â”€ dags/                # OrquestaciÃ³n (DAGs de Airflow)
â”œâ”€â”€ data/                # Data Lake Local
â”‚   â”œâ”€â”€ bronze/          # Raw JSONs
â”‚   â”œâ”€â”€ silver/          # Datos Limpios (Particionados)
â”‚   â”‚   â””â”€â”€ year=YYYY/month=MM/day=DD/
â”‚   â””â”€â”€ gold/            # Reportes de Negocio
â”‚       â”œâ”€â”€ ranking/     # Top contaminaciÃ³n (.csv)
â”‚       â””â”€â”€ summary/     # Promedios por paÃ­s (.csv)
â”œâ”€â”€ pipeline/            # CÃ³digo fuente modular
â”‚   â”œâ”€â”€ ingestion/       # batch_ingest.py
â”‚   â”œâ”€â”€ transform/       # batch_transform.py
â”‚   â”œâ”€â”€ load/            # load_database.py
â”‚   â””â”€â”€ reports_to_gold/ # gold_report.py
â”œâ”€â”€ pytests/             # Pruebas unitarias
â”œâ”€â”€ Dockerfile           # Imagen del entorno
â”œâ”€â”€ docker-compose.yml   # ConfiguraciÃ³n Docker


